{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“kaggle project (count paperclips)\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4vwMJJObfPa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "7e456207-dd1f-4853-feb6-f376bbb7db3f"
      },
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Note: using Google CoLab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJtYKm4u_Udy"
      },
      "source": [
        "1、Download the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7rRNY1mO7ps",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "4e0c3497-73dc-45b7-f9c7-a8f8d62d2f93"
      },
      "source": [
        "!wget https://www.dropbox.com/s/t1a61exycm537v5/clips-data-2020.zip?dl=0\n",
        "!mv clips-data-2020.zip?dl=0 clips-data-2020.zip\n",
        "!unzip -o clips-data-2020.zip > /dev/null\n",
        "print(\"complete\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-14 04:46:04--  https://www.dropbox.com/s/t1a61exycm537v5/clips-data-2020.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:601b:1::a27d:801\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/t1a61exycm537v5/clips-data-2020.zip [following]\n",
            "--2020-04-14 04:46:04--  https://www.dropbox.com/s/raw/t1a61exycm537v5/clips-data-2020.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc719f27e8750e87efdf43266dca.dl.dropboxusercontent.com/cd/0/inline/A1w2nw-N3ZLYbJmt4Bb6xuaiGZLp-7u1k65tXVBL7nXcfPo5t7Q27ZjgDF9-W5yA62GtS3kTxSmC1id7ghPFTM7nH72W2uo5UJAo5yFBj23gpvs0OpA209IG7ODGHo0GkFo/file# [following]\n",
            "--2020-04-14 04:46:04--  https://uc719f27e8750e87efdf43266dca.dl.dropboxusercontent.com/cd/0/inline/A1w2nw-N3ZLYbJmt4Bb6xuaiGZLp-7u1k65tXVBL7nXcfPo5t7Q27ZjgDF9-W5yA62GtS3kTxSmC1id7ghPFTM7nH72W2uo5UJAo5yFBj23gpvs0OpA209IG7ODGHo0GkFo/file\n",
            "Resolving uc719f27e8750e87efdf43266dca.dl.dropboxusercontent.com (uc719f27e8750e87efdf43266dca.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601b:6::a27d:806\n",
            "Connecting to uc719f27e8750e87efdf43266dca.dl.dropboxusercontent.com (uc719f27e8750e87efdf43266dca.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/A1wciSwZDpmRlB8cOSdVFA0GHXhjJWrqZWSCmMYmqhLZ5yw0i7va2gwBcV-pPerNTePcPmA7GJFqbyipL9kjNqJHKzg_tN8h8vhOliQKlgDkDMT9yIo3wKw_yrl8T8FIKndI6fUbZDgWGXK3XyaAw3SDvMkvShvZx-qLwf0O0vY7tZpa8Bon8-ZpAyKpqRarfDQLyUrqKETiNxhrgDfcArUtOD8A82Iq4IsQGERGPDgdHNkjrq0RpvBgoePzZ9qOmxniX0hzXPBAEt6ro3n9SHdqVoDwxji8mydRvB1trPLyBAZEDCRNTFv-r6A7faLuha6kJXfkiRc2xtyAY-W9c9VY0Jgi8-EJ1SIfa0ayMesIHw/file [following]\n",
            "--2020-04-14 04:46:05--  https://uc719f27e8750e87efdf43266dca.dl.dropboxusercontent.com/cd/0/inline2/A1wciSwZDpmRlB8cOSdVFA0GHXhjJWrqZWSCmMYmqhLZ5yw0i7va2gwBcV-pPerNTePcPmA7GJFqbyipL9kjNqJHKzg_tN8h8vhOliQKlgDkDMT9yIo3wKw_yrl8T8FIKndI6fUbZDgWGXK3XyaAw3SDvMkvShvZx-qLwf0O0vY7tZpa8Bon8-ZpAyKpqRarfDQLyUrqKETiNxhrgDfcArUtOD8A82Iq4IsQGERGPDgdHNkjrq0RpvBgoePzZ9qOmxniX0hzXPBAEt6ro3n9SHdqVoDwxji8mydRvB1trPLyBAZEDCRNTFv-r6A7faLuha6kJXfkiRc2xtyAY-W9c9VY0Jgi8-EJ1SIfa0ayMesIHw/file\n",
            "Reusing existing connection to uc719f27e8750e87efdf43266dca.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1775452805 (1.7G) [application/zip]\n",
            "Saving to: ‘clips-data-2020.zip?dl=0’\n",
            "\n",
            "clips-data-2020.zip 100%[===================>]   1.65G  32.9MB/s    in 50s     \n",
            "\n",
            "2020-04-14 04:46:55 (33.9 MB/s) - ‘clips-data-2020.zip?dl=0’ saved [1775452805/1775452805]\n",
            "\n",
            "complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgLLDcu1igeh"
      },
      "source": [
        "2、Next, we build a dataframe that contains the filenames and the clip_count.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVjC5i3B8j2k"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/kaggle_paperclip/train.csv\", \n",
        "    na_values=['NA', '?'])\n",
        "\n",
        "df['filename']=\"clips-\"+df[\"id\"].astype(str)+\".png\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2WuwUA8in-A"
      },
      "source": [
        "3、Separate into a training and validation (for early stopping)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kptA9LNESZBR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7f5431e7-3387-4fe3-8e3d-835e604817d4"
      },
      "source": [
        "TRAIN_PCT = 0.9\n",
        "TRAIN_CUT = int(len(df) * TRAIN_PCT)\n",
        "\n",
        "df_train = df[0:TRAIN_CUT]\n",
        "df_validate = df[TRAIN_CUT:]\n",
        "\n",
        "print(f\"Training size: {len(df_train)}\")\n",
        "print(f\"Validate size: {len(df_validate)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training size: 18000\n",
            "Validate size: 2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On-mz3X8iwZK"
      },
      "source": [
        "4、Create DataGenerators for training and validation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUitfsjtft_s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "97a60619-d1e5-4abf-8f01-c68d9bdeb95c"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras_preprocessing\n",
        "from keras_preprocessing import image\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGES_DIR = \"/content/clips\"\n",
        "\n",
        "training_datagen = ImageDataGenerator(\n",
        "  rescale = 1./255,\n",
        "  horizontal_flip=True,\n",
        "  vertical_flip=True,\n",
        "  fill_mode='nearest')\n",
        "\n",
        "train_generator = training_datagen.flow_from_dataframe(\n",
        "        dataframe=df_train,\n",
        "        directory=IMAGES_DIR,\n",
        "        x_col=\"filename\",\n",
        "        y_col=\"clip_count\",\n",
        "        target_size=(150, 150),\n",
        "        batch_size=16,\n",
        "        class_mode='other')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "val_generator = validation_datagen.flow_from_dataframe(\n",
        "        dataframe=df_validate,\n",
        "        directory=IMAGES_DIR,\n",
        "        x_col=\"filename\",\n",
        "        y_col=\"clip_count\",\n",
        "        target_size=(150, 150),\n",
        "        class_mode='other')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 18000 validated image filenames.\n",
            "Found 2000 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhlxVGaCEjTE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d0aea86-7e18-41a7-d47c-ef7e65b0ac75"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "epoch_steps = 1000 # len(df_train)\n",
        "validation_steps = len(df_validate)\n",
        "model.compile(loss = 'mean_squared_error', optimizer='adam')\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto',\n",
        "        restore_best_weights=True)\n",
        "history = model.fit(train_generator,  \n",
        "  steps_per_epoch=epoch_steps, validation_steps=validation_steps, verbose = 1, \n",
        "  callbacks=[monitor], validation_data=val_generator, epochs=25)\n",
        "# "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              12846080  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 13,627,137\n",
            "Trainable params: 13,627,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "1000/1000 [==============================] - 221s 221ms/step - loss: 118.2412 - val_loss: 78.1488\n",
            "Epoch 2/25\n",
            "1000/1000 [==============================] - 219s 219ms/step - loss: 24.8024 - val_loss: 16.8566\n",
            "Epoch 3/25\n",
            "1000/1000 [==============================] - 219s 219ms/step - loss: 19.2919 - val_loss: 16.0999\n",
            "Epoch 4/25\n",
            "1000/1000 [==============================] - 220s 220ms/step - loss: 14.4013 - val_loss: 13.7731\n",
            "Epoch 5/25\n",
            "1000/1000 [==============================] - 218s 218ms/step - loss: 28.1684 - val_loss: 25.7817\n",
            "Epoch 6/25\n",
            "1000/1000 [==============================] - 217s 217ms/step - loss: 18.2418 - val_loss: 18.1410\n",
            "Epoch 7/25\n",
            "1000/1000 [==============================] - 218s 218ms/step - loss: 12.9034 - val_loss: 10.5610\n",
            "Epoch 8/25\n",
            "1000/1000 [==============================] - 219s 219ms/step - loss: 11.6291 - val_loss: 13.3458\n",
            "Epoch 9/25\n",
            "1000/1000 [==============================] - 219s 219ms/step - loss: 10.3761 - val_loss: 9.0807\n",
            "Epoch 10/25\n",
            "1000/1000 [==============================] - 217s 217ms/step - loss: 24.0845 - val_loss: 20.1018\n",
            "Epoch 11/25\n",
            "1000/1000 [==============================] - 217s 217ms/step - loss: 13.1737 - val_loss: 11.3766\n",
            "Epoch 12/25\n",
            "1000/1000 [==============================] - 217s 217ms/step - loss: 12.0587 - val_loss: 14.5576\n",
            "Epoch 13/25\n",
            "1000/1000 [==============================] - 217s 217ms/step - loss: 10.9374 - val_loss: 16.2866\n",
            "Epoch 14/25\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 11.3215Restoring model weights from the end of the best epoch.\n",
            "1000/1000 [==============================] - 217s 217ms/step - loss: 11.3215 - val_loss: 10.6957\n",
            "Epoch 00014: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfSV7PKYW8X1"
      },
      "source": [
        "5、Generate Submission File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE4Rh9yOOPIM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d3a21827-c7dd-49fa-f1b4-fe821aa0570e"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
        "\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n",
        "\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n",
        "\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dense(1000, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "epoch_steps = 1000 # len(df_train)\n",
        "validation_steps = len(df_validate)\n",
        "model.compile(loss = 'mean_squared_error', optimizer='adam')\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto',\n",
        "        restore_best_weights=True)\n",
        "history = model.fit(train_generator,  \n",
        "  steps_per_epoch=epoch_steps, validation_steps=validation_steps, verbose = 1, \n",
        "  callbacks=[monitor], validation_data=val_generator, epochs=25)\n",
        "#"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_16 (Conv2D)           (None, 222, 222, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 111, 111, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 109, 109, 128)     73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 54, 54, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 52, 52, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 50, 50, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 25, 25, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 23, 23, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 21, 21, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 10, 10, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 4096)              18878464  \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1)                 1001      \n",
            "=================================================================\n",
            "Total params: 48,978,257\n",
            "Trainable params: 48,978,257\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "1000/1000 [==============================] - 277s 277ms/step - loss: 2957.5869 - val_loss: 33.2320\n",
            "Epoch 2/25\n",
            "1000/1000 [==============================] - 276s 276ms/step - loss: 43.7104 - val_loss: 22.9853\n",
            "Epoch 3/25\n",
            "1000/1000 [==============================] - 280s 280ms/step - loss: 34.0248 - val_loss: 22.2569\n",
            "Epoch 4/25\n",
            "1000/1000 [==============================] - 278s 278ms/step - loss: 30.8542 - val_loss: 69.1876\n",
            "Epoch 5/25\n",
            "1000/1000 [==============================] - 276s 276ms/step - loss: 25.1066 - val_loss: 18.2743\n",
            "Epoch 6/25\n",
            "1000/1000 [==============================] - 278s 278ms/step - loss: 24.5275 - val_loss: 18.2720\n",
            "Epoch 7/25\n",
            "1000/1000 [==============================] - 276s 276ms/step - loss: 20.7047 - val_loss: 18.9043\n",
            "Epoch 8/25\n",
            "1000/1000 [==============================] - 275s 275ms/step - loss: 17.2523 - val_loss: 15.1808\n",
            "Epoch 9/25\n",
            "1000/1000 [==============================] - 277s 277ms/step - loss: 18.9043 - val_loss: 13.3539\n",
            "Epoch 10/25\n",
            "1000/1000 [==============================] - 276s 276ms/step - loss: 16.4728 - val_loss: 14.7802\n",
            "Epoch 11/25\n",
            "1000/1000 [==============================] - 275s 275ms/step - loss: 14.1362 - val_loss: 19.4960\n",
            "Epoch 12/25\n",
            "1000/1000 [==============================] - 277s 277ms/step - loss: 327.2296 - val_loss: 483.8750\n",
            "Epoch 13/25\n",
            "1000/1000 [==============================] - 275s 275ms/step - loss: 488.2631 - val_loss: 486.0050\n",
            "Epoch 14/25\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 489.7291Restoring model weights from the end of the best epoch.\n",
            "1000/1000 [==============================] - 273s 273ms/step - loss: 489.7291 - val_loss: 492.0244\n",
            "Epoch 00014: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWFYuAI7W6LI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73a6bce4-d733-4b2c-b5bf-834b51af6aac"
      },
      "source": [
        "df_test = pd.read_csv(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/kaggle_paperclip/test.csv\", \n",
        "    na_values=['NA', '?'])\n",
        "\n",
        "df_test['filename']=\"clips-\"+df_test[\"id\"].astype(str)+\".png\"\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "test_generator = validation_datagen.flow_from_dataframe(\n",
        "        dataframe=df_test,\n",
        "        directory=IMAGES_DIR,\n",
        "        x_col=\"filename\",\n",
        "        batch_size=1,\n",
        "        shuffle=False,\n",
        "        target_size=(150, 150),\n",
        "        class_mode=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5000 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6-2QRcBc7Tc"
      },
      "source": [
        "test_generator.reset()\n",
        "pred = model.predict(test_generator,steps=len(df_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qzoXL5VejB9"
      },
      "source": [
        "df_submit = pd.DataFrame({'id':df_test['id'],'clip_count':pred.flatten()})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiTMdHevooKc"
      },
      "source": [
        "df_submit.to_csv(\"/content/drive/My Drive/Colab Notebooks/kaggle_paperclip/submit5.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}